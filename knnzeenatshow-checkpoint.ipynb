{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "90fdb339",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c5d75254",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Fish2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "cb554661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Weight  Length1  Length2  Length3   Height   Width Species\n",
      "0   242.0     23.2     25.4     30.0  11.5200  4.0200   Bream\n",
      "1   290.0     24.0     26.3     31.2  12.4800  4.3056   Bream\n",
      "2   340.0     23.9     26.5     31.1  12.3778  4.6961   Bream\n",
      "3   363.0     26.3     29.0     33.5  12.7300  4.4555   Bream\n",
      "4   430.0     26.5     29.0     34.0  12.4440  5.1340   Bream\n"
     ]
    }
   ],
   "source": [
    "print(dataset.head()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "61013886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "list_of_index = [i for i in range( len(dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8f13b538",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(dataset,seed_value,k):\n",
    "    random.seed(seed_value)\n",
    "    test_index = random.choices(population=list_of_index,k=k)\n",
    "    test_data = dataset.loc[test_index]\n",
    "    train_data = dataset.drop(index=test_index)\n",
    "    X_train = train_data.iloc[:,:-1].values\n",
    "    X_test = test_data.iloc[:,:-1].values\n",
    "    y_train = train_data['Species'].values\n",
    "    y_test = test_data['Species'].values\n",
    "    return X_train,X_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f5e0a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(dataset,0,70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "741342c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eudlecian_distance(x1,x2):\n",
    "#     print('x=',x1,'y=',x2)\n",
    "#     print(np.sqrt(np.sum((x1-x2)**2)))\n",
    "    return np.sqrt(np.sum((x1-x2)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "600090e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "853eb699",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x_test,k=5):\n",
    "    #calculating distance\n",
    "    distances = [eudlecian_distance(x_test,x_train) for x_train in X_train]\n",
    "    #know lets take the k nearest sample\n",
    "    order_asc_distance = np.argsort(distances) #sorting the distance in asc order\n",
    "   # print(order_asc_distance[:k])\n",
    "    finding_target = [y_train[i] for i in order_asc_distance[:k] ]\n",
    "    print(finding_target)\n",
    "    #majority neighbour for this we will use counter module from collection\n",
    "    most_near_classes = Counter(finding_target).most_common(1)\n",
    "   # print(most_near_classes)\n",
    "    return most_near_classes[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "97c92274",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bream', 'Bream', 'Pike', 'Bream', 'Bream']\n",
      "['Bream', 'Perch', 'Bream', 'Bream', 'Pike']\n",
      "['Parkki', 'Perch', 'Parkki', 'Perch', 'Roach']\n",
      "['Perch', 'Perch', 'Roach', 'Perch', 'Perch']\n",
      "['Perch', 'Perch', 'Perch', 'Roach', 'Perch']\n",
      "['Roach', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Perch', 'Whitefish', 'Bream', 'Perch', 'Bream']\n",
      "['Parkki', 'Roach', 'Roach', 'Perch', 'Roach']\n",
      "['Parkki', 'Perch', 'Roach', 'Roach', 'Perch']\n",
      "['Roach', 'Parkki', 'Parkki', 'Roach', 'Roach']\n",
      "['Pike', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Perch', 'Perch', 'Perch', 'Roach', 'Perch']\n",
      "['Parkki', 'Roach', 'Parkki', 'Perch', 'Perch']\n",
      "['Bream', 'Perch', 'Bream', 'Bream', 'Pike']\n",
      "['Perch', 'Perch', 'Parkki', 'Roach', 'Roach']\n",
      "['Roach', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Pike', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt']\n",
      "['Perch', 'Perch', 'Perch', 'Perch', 'Parkki']\n",
      "['Pike', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Roach', 'Roach', 'Parkki', 'Roach', 'Parkki']\n",
      "['Bream', 'Perch', 'Bream', 'Bream', 'Pike']\n",
      "['Pike', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Whitefish', 'Perch', 'Perch', 'Bream', 'Pike']\n",
      "['Parkki', 'Perch', 'Roach', 'Roach', 'Perch']\n",
      "['Bream', 'Perch', 'Perch', 'Bream', 'Bream']\n",
      "['Perch', 'Perch', 'Perch', 'Perch', 'Parkki']\n",
      "['Parkki', 'Roach', 'Parkki', 'Perch', 'Roach']\n",
      "['Smelt', 'Smelt', 'Perch', 'Smelt', 'Smelt']\n",
      "['Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt']\n",
      "['Parkki', 'Perch', 'Roach', 'Roach', 'Perch']\n",
      "['Pike', 'Bream', 'Bream', 'Perch', 'Bream']\n",
      "['Perch', 'Perch', 'Roach', 'Perch', 'Perch']\n",
      "['Perch', 'Whitefish', 'Bream', 'Perch', 'Bream']\n",
      "['Perch', 'Roach', 'Perch', 'Perch', 'Perch']\n",
      "['Bream', 'Pike', 'Bream', 'Whitefish', 'Perch']\n",
      "['Perch', 'Bream', 'Perch', 'Bream', 'Bream']\n",
      "['Perch', 'Perch', 'Perch', 'Perch', 'Roach']\n",
      "['Pike', 'Perch', 'Whitefish', 'Perch', 'Bream']\n",
      "['Perch', 'Perch', 'Perch', 'Whitefish', 'Whitefish']\n",
      "['Perch', 'Perch', 'Perch', 'Perch', 'Perch']\n",
      "['Perch', 'Perch', 'Roach', 'Parkki', 'Perch']\n",
      "['Pike', 'Bream', 'Bream', 'Perch', 'Bream']\n",
      "['Perch', 'Perch', 'Perch', 'Roach', 'Perch']\n",
      "['Perch', 'Parkki', 'Perch', 'Roach', 'Roach']\n",
      "['Bream', 'Perch', 'Pike', 'Whitefish', 'Bream']\n",
      "['Bream', 'Bream', 'Bream', 'Pike', 'Bream']\n",
      "['Perch', 'Perch', 'Perch', 'Roach', 'Perch']\n",
      "['Perch', 'Perch', 'Roach', 'Parkki', 'Perch']\n",
      "['Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt']\n",
      "['Perch', 'Whitefish', 'Bream', 'Perch', 'Bream']\n",
      "['Perch', 'Perch', 'Whitefish', 'Bream', 'Roach']\n",
      "['Bream', 'Bream', 'Bream', 'Perch', 'Pike']\n",
      "['Perch', 'Perch', 'Perch', 'Perch', 'Parkki']\n",
      "['Perch', 'Perch', 'Perch', 'Roach', 'Perch']\n",
      "['Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt']\n",
      "['Bream', 'Perch', 'Perch', 'Bream', 'Bream']\n",
      "['Perch', 'Roach', 'Perch', 'Perch', 'Perch']\n",
      "['Perch', 'Bream', 'Bream', 'Perch', 'Bream']\n",
      "['Perch', 'Roach', 'Perch', 'Perch', 'Perch']\n",
      "['Pike', 'Perch', 'Whitefish', 'Perch', 'Roach']\n",
      "['Perch', 'Perch', 'Perch', 'Roach', 'Perch']\n",
      "['Smelt', 'Smelt', 'Smelt', 'Smelt', 'Smelt']\n",
      "['Parkki', 'Roach', 'Roach', 'Perch', 'Roach']\n",
      "['Parkki', 'Roach', 'Parkki', 'Perch', 'Roach']\n",
      "['Whitefish', 'Roach', 'Whitefish', 'Perch', 'Perch']\n",
      "['Roach', 'Parkki', 'Parkki', 'Roach', 'Roach']\n",
      "['Parkki', 'Roach', 'Roach', 'Perch', 'Perch']\n",
      "['Perch', 'Perch', 'Perch', 'Perch', 'Roach']\n",
      "['Perch', 'Parkki', 'Roach', 'Perch', 'Parkki']\n"
     ]
    }
   ],
   "source": [
    "pre_list = []\n",
    "for i in X_test[:]:\n",
    "    dis = predict(i,k=5) \n",
    "    pre_list.append(dis) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ad9f1622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">prdicted= ['Bream', 'Bream', 'Parkki', 'Perch', 'Perch', 'Perch', 'Perch', 'Roach', 'Perch', 'Roach', 'Perch', 'Perch', 'Parkki', 'Bream', 'Perch', 'Perch', 'Perch', 'Smelt', 'Perch', 'Perch', 'Roach', 'Bream', 'Perch', 'Perch', 'Perch', 'Bream', 'Perch', 'Parkki', 'Smelt', 'Smelt', 'Perch', 'Bream', 'Perch', 'Perch', 'Perch', 'Bream', 'Bream', 'Perch', 'Perch', 'Perch', 'Perch', 'Perch', 'Bream', 'Perch', 'Perch', 'Bream', 'Bream', 'Perch', 'Perch', 'Smelt', 'Perch', 'Perch', 'Bream', 'Perch', 'Perch', 'Smelt', 'Bream', 'Perch', 'Bream', 'Perch', 'Perch', 'Perch', 'Smelt', 'Roach', 'Parkki', 'Whitefish', 'Roach', 'Roach', 'Perch', 'Perch']\n"
     ]
    }
   ],
   "source": [
    "print('>prdicted=',pre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "04c52e8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">actual= ['Pike' 'Perch' 'Parkki' 'Roach' 'Perch' 'Parkki' 'Perch' 'Roach' 'Perch'\n",
      " 'Perch' 'Pike' 'Perch' 'Roach' 'Perch' 'Perch' 'Roach' 'Pike' 'Smelt'\n",
      " 'Pike' 'Pike' 'Roach' 'Perch' 'Pike' 'Perch' 'Perch' 'Bream' 'Parkki'\n",
      " 'Perch' 'Smelt' 'Smelt' 'Perch' 'Pike' 'Roach' 'Perch' 'Perch' 'Bream'\n",
      " 'Perch' 'Parkki' 'Pike' 'Perch' 'Bream' 'Perch' 'Pike' 'Roach' 'Roach'\n",
      " 'Pike' 'Bream' 'Perch' 'Roach' 'Smelt' 'Perch' 'Parkki' 'Bream' 'Roach'\n",
      " 'Perch' 'Smelt' 'Bream' 'Perch' 'Perch' 'Perch' 'Pike' 'Perch' 'Smelt'\n",
      " 'Perch' 'Perch' 'Parkki' 'Perch' 'Parkki' 'Perch' 'Roach']\n"
     ]
    }
   ],
   "source": [
    "print('>actual=',y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "891c8f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4714285714285714"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(list_sum)/len(y_test) # shows that all of our prediction are correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead64fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "ca51ca9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11d44c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bd9a98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399c79a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59553ecd444ac45b306ef4cf917906ee1e090f0cd110d592cae35eebc5ede51d"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
